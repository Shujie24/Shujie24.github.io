---
title: "Logical Reasoning in Large Language Models"
excerpt: "Benchmarking and enhancing LLMs' logical reasoning abilities using RAG and z3 solvers"
collection: portfolio
---

## Project Overview
Research project at Vector Institute focused on benchmarking and enhancing Large Language Models' logical reasoning abilities with few-shot learning and Retrieval Augmented Generation (RAG).

## Key Contributions
- **Benchmarking**: Led comprehensive evaluation of LLMs' logical reasoning capabilities across multiple datasets
- **RAG Integration**: Built pipeline integrating LLMs with z3 solvers using Retrieval Augmented Generation
- **Performance Improvements**: Achieved significant accuracy improvements:
  - ProofWriter: +16.7%
  - LogicalDeduction: +8.7%
  - FOLIO: +5.5%
  - ProntoQA: +0.4%

## Technologies Used
- Large Language Models (various architectures)
- z3 solver
- Retrieval Augmented Generation (RAG)
- Few-shot learning techniques
- Python, PyTorch 